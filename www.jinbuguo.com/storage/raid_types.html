<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-CN">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Language" content="zh-CN" />
<!--[if lt IE 9]><style type="text/css">@font-face { font-family: "JinBuGuoWebMono"; src: url("/d/mono.eot"); }</style><![endif]-->
<style media="all" type="text/css">
@font-face { font-family: "JinBuGuoWebMono"; src: url("/d/mono.ttf") format("truetype"); }
* { font-family: "JinBuGuoWebMono", "Ubuntu Mono", "Consolas", "Menlo", monospace; }
body { margin:10px; }
h1,h2 { text-align:center; background:#ddd; }
h2 { margin: 10px 5%; }
h2#auth_name {  background:#fff; }
dt { margin-top: 0.5em; color:#600; }
pre { background: #edc; }
</style>
<title>三种 Linux RAID 简要说明 [金步国]</title>
<script>var _hmt=_hmt||[]; (function(){ var hm=document.createElement("script"); hm.src="//hm.baidu.com/hm.js?d286c55b63a3c54a1e43d10d4c203e75"; var s=document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm,s); })();</script>
</head>

<body>
<h1>三种 Linux RAID 简要说明</h1><h2 id="auth_name">作者：<strong><a href="http://www.jinbuguo.com/">金步国</a></strong></h2>
<hr />
<h3>版权声明</h3>
<p>本文作者是一位开源理念的坚定支持者，所以本文虽然不是软件，但是遵照开源的精神发布。</p>
<ul>
<li>无担保：本文作者不保证作品内容准确无误，亦不承担任何由于使用此文档所导致的损失。</li>
<li>自由使用：任何人都可以自由的<u>阅读/链接/打印</u>此文档，无需任何附加条件。</li>
<li>名誉权：任何人都可以自由的<u>转载/引用/再创作</u>此文档，但必须保留作者署名并注明出处。</li>
</ul>
<h3>其他作品</h3>
<p>本文作者十分愿意与他人分享劳动成果，如果你对我的其他翻译作品或者技术文章有兴趣，可以在如下位置查看现有的作品集：</p>
<ul>
<li><a href="http://www.jinbuguo.com/">金步国作品集</a> [ <a href="http://www.jinbuguo.com/">http://www.jinbuguo.com/</a> ]</li>
</ul>
<h3>联系方式</h3>
<p>由于作者水平有限，因此不能保证作品内容准确无误。如果你发现了作品中的错误(哪怕是错别字也好)，请来信指出，任何提高作品质量的建议我都将虚心接纳。</p>
<ul>
<li>Email(QQ)：70171448在QQ邮箱</li>
</ul>
<hr />




<h2>概述</h2>
<p>Linux上的RAID有三种：</p>
<dl>
<dt>硬RAID(hard-RAID)</dt>
<dd>通过专门的RAID控制芯片实现。一般表现为RAID卡，并且卡上有专用的、独立于主板BIOS的固件(一般也称其为BIOS)。</dd>
<dt>伪RAID(fake-RAID)</dt>
<dd>通过SATA/IDE等磁盘控制芯片附带的RAID固件(集成于主板的BIOS中)实现，所以又称为"bios-RAID"。典型的例子就是Intel ICHxR系列南桥芯片。</dd>
<dt>软RAID(soft-RAID)</dt>
<dd>完全通过操作系统内核实现的RAID。不需要任何额外的辅助硬件。</dd>
</dl>
<p>硬RAID在性能上是最好的，所有RAID操作都由RAID控制芯片完成，不占用任何CPU和内存资源，而且RAID卡上一般还有额外的缓存进一步提升性能。对于操作系统和主板上的BIOS而言，硬RAID和一块普通的硬盘没有任何差别。但硬RAID的劣势也在于它的完全独立性，由于它完全依赖硬件实现，我们无法知道其精确的内部工作方式，而且RAID配置信息也保存在这块卡上，万一RAID卡自身损坏的话，硬盘中的数据恢复就没有那么容易了。</p>
<p>至于fake-RAID和soft-RAID，两者本质上都是利用CPU资源进行RAID操作，在性能上差距很小，对操作系统也都不是完全透明的。但本文作者推荐使用软RAID而不是伪RAID，理由如下：</p>
<ul>
<li>对于软RAID来说，因为它跟硬件没有任何关系，并且它的配置信息也是保存在硬盘上的，所以即使主板坏了，把硬盘拿到另一个Linux系统下照样可以读出正确数据来。</li>
<li>对于伪RAID来说，因为它与硬RAID有类似的硬件依赖性，并且它的配置信息是保存在主板上的，所以如果主板坏了，必须把硬盘拿到相同芯片组的主板上，并且正确恢复RAID配置信息之后，才能读出正确数据来。</li>
<li>伪RAID的性能并不比软RAID有优势。</li>
</ul>


<h2>内核配置</h2>
<p>三种不同的RAID，在内核配置上也各不相同，具体如下：</p>


<h3>硬RAID(hard-RAID)</h3>
<p>
硬RAID比较简单。由于所有RAID操作都由RAID控制芯片完成，硬RAID和一块普通的硬盘没有任何差别，只要内核能够跟控制芯片正常通讯即可。所以在内核配置时，只需要在
<pre>
Device Drivers
  ->SCSI device support
    ->SCSI low-level drivers
</pre>
目录中选取所需RAID卡的驱动即可。哪怕在
<pre>
Device Drivers
  ->Multiple devices driver support (RAID and LVM)
</pre>
和
<pre>
Device Drivers
  ->SCSI device support
    ->RAID Transport Class
</pre>
下什么都不选，也完全没有任何问题。
</p>
<p>最后，硬RAID在系统中也表现为"/dev/sda"这样的设备，和普通的硬盘完全看不出任何差别。</p>


<h3>伪RAID(fake-RAID)</h3>
<p>对于fake-RAID而言，芯片组的固件只负责内核加载之前对RAID阵列的管理，而内核加载之后，对RAID的控制就移交给内核和CPU了。</p>
<p>
首先，因为没有真正的RAID控制芯片，所以不需要"SCSI low-level drivers"；<br>
其次，由于fake-RAID是通过内核的Device mapper实现的，所以在内核配置时，需要选中
<pre>
Device Drivers
  ->Multiple devices driver support (RAID and LVM)
    ->Device mapper support
      ->[*]RAID 1/4/5/6/10 target
</pre>
此外，内核还必须添加SATA驱动才行。所以还需要选中
<pre>
Device Drivers
  ->Serial ATA and Parallel ATA drivers
    ->[*]AHCI SATA support
</pre>
最后，由于是通过 /dev/mapper/ 而不是 /dev/md* 来管理RAID，所以不需要选中
<pre>
Device Drivers
  ->Multiple devices driver support (RAID and LVM)
    ->RAID support
</pre>
及其任何子项。
</p>
<p>在具体使用上，因为fake-RAID必须使用<a href="http://people.redhat.com/heinzm/sw/dmraid/">dmraid</a>工具启动之后才能使用，所以如果根文件系统位于fake-RAID上，就必须要通过initramfs的辅助才能挂载。比较麻烦。</p>


<h3>软RAID(soft-RAID)</h3>
<p>
对于完全由内核来实现的软RAID来说，在内核配置时，除了显然必须的SATA/SCSI磁盘驱动之外，只需要额外加上
<pre>
Device Drivers
  ->Multiple devices driver support (RAID and LVM)
    ->RAID support
</pre>
中相应的子项即可。并不需要再添加其他选项。
</p>
<p>在具体使用上，soft-RAID使用<a href="https://www.kernel.org/pub/linux/utils/raid/mdadm/">mdadm</a>工具进行创建和管理。相应的设备文件是 /dev/mdN ，这里的N是[0-225]之间的整数。</p>
<p>soft-RAID的用法也比较灵活，既可以将多个磁盘分区(需要将分区类型设为"fd")组合成RAID使用，也可以将多个物理磁盘组合成RAID使用。</p>
<p>此外，soft-RAID的另一个优势在于：soft-RAID并不需要专门的工具来"启动"，内核甚至能够自动检测RAID的配置。所以即使根文件系统位于soft-RAID上，也不需要initramfs的辅助(但有可能需要"md="引导参数)。</p>
<h4>释疑</h4>
<p>
熟悉Gentoo的朋友，可能会对官方<a href="http://www.gentoo.org/doc/en/gentoo-x86+raid+lvm2-quickinstall.xml">《在软RAID和LVM2上安装Gentoo》</a>文档中把
<pre>
Device Drivers
  ->Multiple devices driver support (RAID and LVM)
    ->[*]Device mapper support
</pre>
也选上感到困惑不解。上文不是说软RAID只需要"RAID support"就OK了吗？怎么又加上"Device mapper support"了呢？真实的原因在于手册中的例子同时使用了soft-RAID和LVM，而LVM跟fake-RAID一样，都是基于Device mapper的，选中"Device mapper support"只是为了给LVM提供支持，与soft-RAID并无瓜葛。
</p>
<p>
另外，对内核选项比较熟悉的朋友，可能还有一个疑惑：内核中不是还有一个
<pre>
Device Drivers
  ->SCSI device support
    ->RAID Transport Class
</pre>
选项吗？怎么和前面提到的各种RAID都没沾上边呢？事实上，这个选项(drivers/scsi/raid_class.c)只是一个用来得到RAID信息的一个类而已，目前而言，不管你的系统使用的是哪种RAID，都可以放心的关闭此项，而不会对RAID的运作有什么影响。
</p>

<hr />

</body></html>